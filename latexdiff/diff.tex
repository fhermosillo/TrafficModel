%  LaTeX support: latex@mdpi.com 
%DIF LATEXDIFF DIFFERENCE FILE
%DIF DEL D:/CINVESTAV/Doctorado/Cuatrimestre/7/Dr Deni/TrafficModel/tmp.old.tex                 Fri Oct 16 12:19:28 2020
%DIF ADD D:/CINVESTAV/Doctorado/Cuatrimestre/7/Dr Deni/TrafficModel/Vehicle Traffic Model.tex   Fri Oct 16 11:46:32 2020
%  In case you need support, please attach all files that are necessary for compiling as well as the log file, and specify the details of your LaTeX setup (which operating system and LaTeX version / tools you are using).

%=================================================================
\documentclass[sensors,article,submit,moreauthors,pdftex]{Definitions/mdpi} 





\usepackage{amsmath}
\usepackage[center]{subfigure} %para las subfiguras
\usepackage{multirow}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\mathvec}[1]{\boldsymbol{\mathbf{\MakeLowercase{#1}}}}
\newcommand{\mathmat}[1]{\boldsymbol{\mathbf{\MakeUppercase{#1}}}}
\newcommand{\mathten}[1]{\boldsymbol{\mathbf{\mathcal{\MakeUppercase{#1}}}}}




% If you would like to post an early version of this manuscript as a preprint, you may use preprint as the journal and change 'submit' to 'accept'. The document class line would be, e.g., \documentclass[preprints,article,accept,moreauthors,pdftex]{mdpi}. This is especially recommended for submission to arXiv, where line numbers should be removed before posting. For preprints.org, the editorial staff will make this change immediately prior to posting.

%--------------------
% Class Options:
%--------------------
%----------
% journal
%----------
% Choose between the following MDPI journals:
% acoustics, actuators, addictions, admsci, aerospace, agriculture, agriengineering, agronomy, algorithms, animals, antibiotics, antibodies, antioxidants, applsci, arts, asc, asi, atmosphere, atoms, axioms, batteries, bdcc, behavsci , beverages, bioengineering, biology, biomedicines, biomimetics, biomolecules, biosensors, brainsci , buildings, cancers, carbon , catalysts, cells, ceramics, challenges, chemengineering, chemistry, chemosensors, children, cleantechnol, climate, clockssleep, cmd, coatings, colloids, computation, computers, condensedmatter, cosmetics, cryptography, crystals, dairy, data, dentistry, designs , diagnostics, diseases, diversity, drones, econometrics, economies, education, ejihpe, electrochem, electronics, energies, entropy, environments, epigenomes, est, fermentation, fibers, fire, fishes, fluids, foods, forecasting, forests, fractalfract, futureinternet, futurephys, galaxies, games, gastrointestdisord, gels, genealogy, genes, geohazards, geosciences, geriatrics, hazardousmatters, healthcare, heritage, highthroughput, horticulturae, humanities, hydrology, ijerph, ijfs, ijgi, ijms, ijns, ijtpp, informatics, information, infrastructures, inorganics, insects, instruments, inventions, iot, j, jcdd, jcm, jcp, jcs, jdb, jfb, jfmk, jimaging, jintelligence, jlpea, jmmp, jmse, jnt, jof, joitmc, jpm, jrfm, jsan, land, languages, laws, life, literature, logistics, lubricants, machines, magnetochemistry, make, marinedrugs, materials, mathematics, mca, medicina, medicines, medsci, membranes, metabolites, metals, microarrays, micromachines, microorganisms, minerals, modelling, molbank, molecules, mps, mti, nanomaterials, ncrna, neuroglia, nitrogen, notspecified, nutrients, ohbm, optics, particles, pathogens, pharmaceuticals, pharmaceutics, pharmacy, philosophies, photonics, physics, plants, plasma, polymers, polysaccharides, preprints , proceedings, processes, proteomes, psych, publications, quantumrep, quaternary, qubs, reactions, recycling, religions, remotesensing, reports, resources, risks, robotics, safety, sci, scipharm, sensors, separations, sexes, signals, sinusitis, smartcities, sna, societies, socsci, soilsystems, sports, standards, stats, surfaces, surgeries, sustainability, symmetry, systems, technologies, test, toxics, toxins, tropicalmed, universe, urbansci, vaccines, vehicles, vetsci, vibration, viruses, vision, water, wem, wevj

%---------
% article
%---------
% The default type of manuscript is "article", but can be replaced by: 
% abstract, addendum, article, benchmark, book, bookreview, briefreport, casereport, changes, comment, commentary, communication, conceptpaper, conferenceproceedings, correction, conferencereport, expressionofconcern, extendedabstract, meetingreport, creative, datadescriptor, discussion, editorial, essay, erratum, hypothesis, interestingimages, letter, meetingreport, newbookreceived, obituary, opinion, projectreport, reply, retraction, review, perspective, protocol, shortnote, supfile, technicalnote, viewpoint
% supfile = supplementary materials

%----------
% submit
%----------
% The class option "submit" will be changed to "accept" by the Editorial Office when the paper is accepted. This will only make changes to the frontpage (e.g., the logo of the journal will get visible), the headings, and the copyright information. Also, line numbering will be removed. Journal info and pagination for accepted papers will also be assigned by the Editorial Office.

%------------------
% moreauthors
%------------------
% If there is only one author the class option oneauthor should be used. Otherwise use the class option moreauthors.

%---------
% pdftex
%---------
% The option pdftex is for use with pdfLaTeX. If eps figures are used, remove the option pdftex and use LaTeX and dvi2pdf.

%=================================================================
\firstpage{1} 
\makeatletter 
\setcounter{page}{\@firstpage} 
\makeatother
\pubvolume{xx}
\issuenum{1}
\articlenumber{5}
\pubyear{2019}
\copyrightyear{2019}
%\externaleditor{Academic Editor: name}
\history{Received: date; Accepted: date; Published: date}
%\updates{yes} % If there is an update available, un-comment this line

%% MDPI internal command: uncomment if new journal that already uses continuous page numbers 
%\continuouspages{yes}

%------------------------------------------------------------------
% The following line should be uncommented if the LaTeX file is uploaded to arXiv.org
%\pdfoutput=1

%=================================================================
% Add packages and commands here. The following packages are loaded in our class file: fontenc, calc, indentfirst, fancyhdr, graphicx, lastpage, ifthen, lineno, float, amsmath, setspace, enumitem, mathpazo, booktabs, titlesec, etoolbox, amsthm, hyphenat, natbib, hyperref, footmisc, geometry, caption, url, mdframed, tabto, soul, multirow, microtype, tikz


%=================================================================
%% Please use the following mathematics environments: Theorem, Lemma, Corollary, Proposition, Characterization, Property, Problem, Example, ExamplesandDefinitions, Hypothesis, Remark, Definition, Notation, Assumption
%% For proofs, please use the proof environment (the amsthm package is loaded by the MDPI class).

%=================================================================
% Full title of the paper (Capitalized)
\Title{Tensor Modeling and Analysis for Vehicle Traffic}

% Author Orchid ID: enter ID or remove command
\newcommand{\orcidauthorA}{0000-0000-000-000X} % Add \orcidA{} behind the author's name
%\newcommand{\orcidauthorB}{0000-0000-000-000X} % Add \orcidB{} behind the author's name

% Authors, for the paper (add full first names)
\Author{Hermosillo-Reynoso Fernando $^{1,\ddagger}$*, Torres-Roman Deni $^{1,\ddagger}$}

% Authors, for metadata in PDF
\AuthorNames{Fernando Hermosillo-Reynoso, Deni Torres-Roman}

% Affiliations / Addresses (Add [1] after \address if there is only one affiliation.)
\address{%
	$^{1}$ \quad CINVESTAV IPN Department of Electrical Engineering and Computer Sciences, Telecommunications Section, Guadalajara, Jalisco, Mexico; fhermosillo@gdl.cinvestav.mx; dtorres@gdl.cinvestav.mx}
%$^{1}$ \quad Affiliation 1; e-mail@e-mail.com\\
%$^{2}$ \quad Affiliation 2; e-mail@e-mail.com}

% Contact information of the corresponding author
\corres{Correspondence: fhermosillo@gdl.cinvestav.mx; Tel.: +52-331-631-3095}

% Current address and/or shared authorship
%\firstnote{Current address: Affiliation 3} 
\secondnote{These authors contributed equally to this work.}
% The commands \thirdnote{} till \eighthnote{} are available for further notes

%\simplesumm{} % Simple summary

%\conference{} % An extended version of a conference paper


% Abstract (Do not insert blank lines, i.e. \\) 
\abstract{A single paragraph of about 200 words maximum. For research articles, abstracts should give a pertinent overview of the work. We strongly encourage authors to use the following style of structured abstracts, but without headings: (1) Background: Place the question addressed in a broad context and highlight the purpose of the study; (2) Methods: Describe briefly the main methods or treatments applied; (3) Results: Summarize the article's main findings; and (4) Conclusion: Indicate the main conclusions or interpretations. The abstract should be an objective representation of the article, it must not contain results which are not presented and substantiated in the main text and should not exaggerate the main conclusions.}

% Keywords
\keyword{keyword 1; keyword 2; keyword 3 (list three to ten pertinent keywords specific to the article, yet reasonably common within the subject discipline.)}

% The fields PACS, MSC, and JEL may be left empty or commented out if not applicable
%\PACS{J0101}
%\MSC{}
%\JEL{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Diversity
%\LSID{\url{http://}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Applied Sciences:
%\featuredapplication{Authors are encouraged to provide a concise description of the specific application or a potential application of the work. This section is not mandatory.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Data:
%\dataset{DOI number or link to the deposited data set in cases where the data set is published or set to be published separately. If the data set is submitted and will be published as a supplement to this paper in the journal Data, this field will be filled by the editors of the journal. In this case, please make sure to submit the data set as a supplement when entering your manuscript into our manuscript editorial system.}

%\datasetlicense{license under which the data set is made available (CC0, CC-BY, CC-BY-SA, CC-BY-NC, etc.)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Toxins
%\keycontribution{The breakthroughs or highlights of the manuscript. Authors can write one or two sentences to describe the most important part of the paper.}

%\setcounter{secnumdepth}{4}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF UNDERLINE PREAMBLE %DIF PREAMBLE
\RequirePackage[normalem]{ulem} %DIF PREAMBLE
\RequirePackage{color}\definecolor{RED}{rgb}{1,0,0}\definecolor{BLUE}{rgb}{0,0,1} %DIF PREAMBLE
\providecommand{\DIFadd}[1]{{\protect\color{blue}\uwave{#1}}} %DIF PREAMBLE
\providecommand{\DIFdel}[1]{{\protect\color{red}\sout{#1}}}                      %DIF PREAMBLE
%DIF SAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddbegin}{} %DIF PREAMBLE
\providecommand{\DIFaddend}{} %DIF PREAMBLE
\providecommand{\DIFdelbegin}{} %DIF PREAMBLE
\providecommand{\DIFdelend}{} %DIF PREAMBLE
\providecommand{\DIFmodbegin}{} %DIF PREAMBLE
\providecommand{\DIFmodend}{} %DIF PREAMBLE
%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddFL}[1]{\DIFadd{#1}} %DIF PREAMBLE
\providecommand{\DIFdelFL}[1]{\DIFdel{#1}} %DIF PREAMBLE
\providecommand{\DIFaddbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFaddendFL}{} %DIF PREAMBLE
\providecommand{\DIFdelbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFdelendFL}{} %DIF PREAMBLE
%DIF LISTINGS PREAMBLE %DIF PREAMBLE
\RequirePackage{listings} %DIF PREAMBLE
\RequirePackage{color} %DIF PREAMBLE
\lstdefinelanguage{DIFcode}{ %DIF PREAMBLE
%DIF DIFCODE_UNDERLINE %DIF PREAMBLE
  moredelim=[il][\color{red}\sout]{\%DIF\ <\ }, %DIF PREAMBLE
  moredelim=[il][\color{blue}\uwave]{\%DIF\ >\ } %DIF PREAMBLE
} %DIF PREAMBLE
\lstdefinestyle{DIFverbatimstyle}{ %DIF PREAMBLE
	language=DIFcode, %DIF PREAMBLE
	basicstyle=\ttfamily, %DIF PREAMBLE
	columns=fullflexible, %DIF PREAMBLE
	keepspaces=true %DIF PREAMBLE
} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim}{\lstset{style=DIFverbatimstyle}}{} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim*}{\lstset{style=DIFverbatimstyle,showspaces=true}}{} %DIF PREAMBLE
%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\setcounter{section}{-1} %% Remove this when starting to work on the template.
%\section{How to Use this Template}
%The template details the sections that can be used in a manuscript. Note that the order and names of article sections may differ from the requirements of the journal (e.g., the positioning of the Materials and Methods section). Please check the instructions for authors page of the journal to verify the correct order and names. For any questions, please contact the editorial office of the journal or support@mdpi.com. For LaTeX related questions please contact latex@mdpi.com.
%The order of the section titles is: Introduction, Materials and Methods, Results, Discussion, Conclusions for these journals: aerospace,algorithms,antibodies,antioxidants,atmosphere,axioms,biomedicines,carbon,crystals,designs,diagnostics,environments,fermentation,fluids,forests,fractalfract,informatics,information,inventions,jfmk,jrfm,lubricants,neonatalscreening,neuroglia,particles,pharmaceutics,polymers,processes,technologies,viruses,vision

\section{Introduction}
%The introduction should briefly place the study in a broad context and highlight why it is important. It should define the purpose of the work and its significance. The current state of the research field should be reviewed carefully and key publications cited. Please highlight controversial and diverging hypotheses when necessary. Finally, briefly mention the main aim of the work and highlight the principal conclusions. As far as possible, please keep the introduction comprehensible to scientists outside your particular field of research. Citing a journal paper \cite{ref-journal}. And now citing a book reference \cite{ref-book}. Please use the command \citep{ref-journal} for the following MDPI journals, which use author-date citation: Administrative Sciences, Arts, Econometrics, Economies, Genealogy, Humanities, IJFS, JRFM, Languages, Laws, Religions, Risks, Social Sciences.
Content
\begin{enumerate}[leftmargin=*,labelsep=4.9mm]
\item	Related work.
\item	Contribution.
\item	Content.
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Tensor Algebra}
\label{sec:tensoralg}
\begin{table}[H]
\caption{Tensor Algebra Notation Summary.}
\centering
%% \tablesize{} %% You can specify the fontsize here, e.g., \tablesize{\footnotesize}. If commented out \small will be used.
\begin{tabular}{ll}
\midrule
$\mathten{X}, \mathmat{X}, \mathvec{x}, x$		& Tensor, matrix, vector scalar.\\
$\mathten{X} \in \mathbb{R}^{I_1 \times \cdots \times I_N}$		& A ${I_1 \times \cdots \times I_N}$ tensor.\\
$ord(\mathten{X})$ & The order of a tensor.\\
$x_{i_1 \cdots i_N}$ & The $({i_1 \cdots i_N})$ entry of an $N^{th}$-order tensor.\\
$\mathmat{X}^{(n)}$ & The $n^{th}$ matrix element from a sequence of matrices.\\
$\mathmat{X}_{(n)}$ & The n-mode matricization of a tensor.\\
$\boldsymbol{\otimes}$ & Outer product of two vectors.\\
$\boldsymbol{\otimes}_{kron}$ & Kronecker product of two matrices.\\
$\bigodot$	& Khatri Rao product of two matrices.\\
$\langle \mathten{X}, \mathten{Y} \rangle$ & Inner product of two tensors.\\
$\mathten{Y} = \mathten{X} \times_n \mathmat{U}$ & The n-mode product of a tensor $\mathten{X}$ times a matrix $\mathmat{U}$ along the $n$ dimension.\\
$[\![\boldsymbol{\lambda}/\mathten{G},\mathmat{U}^{(1)},\cdots,\mathmat{U}^{(N)}]\!]$ & Kruskal notation of tensor decomposition models.\\
$rank_{D}(\mathten{X})=R$ & Tensor decomposition/CP rank.\\
$rank_{tc}(\mathten{X})=(R_1,\cdots, R_N)$ & Tensor multilinear/Tucker rank, where $R_n = rank(\mathmat{X}_{(n)})$.\\
$rank_k(\mathten{X})$ & Tensor Kruskal-rank\\
\textemdash\textemdash	 & \textemdash\textemdash\textemdash\textemdash\textemdash\textemdash\textemdash\textemdash\textemdash\\
$\mathten{X} * \mathten{Y}$ & t-product of two tensors.\\
$\mathten{X} *_{\Phi} \mathten{Y}$ & $\Phi$-product of two tensors.\\
\textemdash\textemdash	 & \textemdash\textemdash\textemdash\textemdash\textemdash\textemdash\textemdash\textemdash\textemdash\\
$\mathcal{H}(\cdot)$/$\mathcal{H}^{-1}(\cdot)$ & Hankelization direct/inverse transformation.\\
$\mathcal{L}(\cdot)$/$\mathcal{L}^{-1}(\cdot)$ & L{\"o}wnerization direct/inverse transformation.\\
\textemdash\textemdash	 & \textemdash\textemdash\textemdash\textemdash\textemdash\textemdash\textemdash\textemdash\textemdash\\
$\mathten{V}_\tau$ & Video of duration $\tau$, represented as a tensor.\\
$\mathten{B}$ & Background tensor.\\
$\mathten{F}$ & Foreground tensor.\\
\DIFdelbeginFL \DIFdelFL{$\mathten{T}$ }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{$\mathten{T}^{(N)}$ }\DIFaddendFL & Vehicle traffic \DIFdelbeginFL \DIFdelFL{features tensor }\DIFdelendFL \DIFaddbeginFL \DIFaddFL{feature tensor with $N$ embedded models}\DIFaddendFL .\\
\bottomrule
\end{tabular}
\end{table}

% n-mode product of a tensor $\mathten{X}\in\mathbb{R}^{I_1 \times \cdots \times I_N}$ times a matrix $\mathmat{U} \in \mathbb{R}^{J \times I_n}$ along the n-dimension resulting in a tensor $\mathten{Y} \in \mathbb{R}^{I_1 \times \cdots \times I_{n-1} \times J \times I_{n+1} \times \cdots \times I_N}$.

\begin{enumerate}[leftmargin=*,labelsep=4.9mm]
	\item	Notation.
	\item	Basic tensor concepts.
	\item 	Operators on tensors.
	\item 	Tensorization definition and methods.
	\item	Tensor decompositions (E.G.)
	\begin{enumerate}[leftmargin=*,labelsep=4.9mm]
		\item	CANDECOM/PARAFAC Decomposition
		\item	Tucker Decomposition
		\item	Tensor Robust PCA
		\item	Non-negative Tensor Decomposition
	\end{enumerate}
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem Statement and Mathematical Definition}

Current traffic surveillance systems employ different data models on each stage, so there is no such unified model which allows to capture relationships among all stages. Multidimensional models, have proven to be very powerful for explicitly representing and extracting multidimensional structures in several fields, including signal processing [], machine learning [],  and telecommunications [], to name just a few. Unfortunately, despite its high potential in several fields, multidimensional models have not yet been exploited for the vehicle traffic modeling.



\subsection{Problem Statement}
Given a traffic surveillance video $\mathten{V}_\tau$ of duration $\tau$, we seek to formulate a complete and flexible tensor modeling for the supervision of moving vehicles traffic, which allows us to link various data models involved during the analysis of the moving vehicle behavior and its intrinsic \DIFdelbegin \DIFdel{relations in }\DIFdelend \DIFaddbegin \DIFadd{interactions among multiple }\DIFaddend stages such as: detection, counting, tracking, occlusion management and classification; speed up or facilitate data transformation by using certain mathematical operations of tensor algebra.



\subsection{Mathematical Definition}
The problem raised above can be understood as a multidimensional modeling of moving vehicles which we called Vehicle Traffic Feature (VTF) tensor \DIFaddbegin \DIFadd{model}\DIFaddend , in such a way that each data model employed, can be represented as a mode or dimension, i.e., $\mathten{T} \in \mathbb{R}^{Model\:1 \times Model\:2 \times \cdots \times Model\:N}$. From this model, other representations could be also derived by either fixing certain dimensions or applying some multidimensional operators on it, in order to study the behavior of moving vehicles at specific modes.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Tensor-based Vehicle Traffic Modeling}
Traditional vehicle traffic models treat data as a one-dimensional features vector, to later be used to capture the internal correlation of historical data. However, vehicle traffic data is multi-mode by experiments, e.g., features mode, time mode, vehicle class mode, occlusion mode, among others, therefore, the current models turn out to be inadequate to capture these multidimensional interactions. The proposal of a multidimensional model will preserve the multi-mode nature of data, while the use of tensor methods such as decompositions, will help to better capture correlations among all modes.

\subsection{Traffic Surveillance Video Modeling}

Given a traffic surveillance video modeled as a four-order tensor $\mathten{V}_\tau \in \mathbb{R}^{W\times H \times D \times Time}$ of $W \times H$ resolution and a duration of $\tau$ seconds, \DIFaddbegin \DIFadd{and }\DIFaddend where each pixel is mapped in some color-space of dimension $D$, e.g., grayscale, RGB, then, we will assume that there exist some tensor decomposition model such that the following Equation holds (see Figure \ref{fig:tsvmodel}):

\begin{equation}
\mathten{V}_\tau = \mathten{B} + \mathten{F}
\label{eq:tsvmodel}
\end{equation}

where $\mathten{B} \in \mathbb{R}^{W\times H \times D \times Time}$ is a low-rank tensor which capture low-frequency components the video, i.e., the background, while $\mathten{F} \in \mathbb{R}^{W\times H \times D \times Time}$ is a sparse tensor that contains motion information on the video, in other words it represents the foreground. Note that in Figure \ref{fig:tsvmodel} exists another tensor denoted by $\mathten{F}_m \in \mathbb{R}^{W\times H \times Time}$, which is the binary mask of $\mathten{F}$.

\begin{figure}[H]
\centering
\includegraphics[width=14 cm]{images/traffic-model.png}
\caption{Illustration of the traffic surveillance video decomposition model.}
\label{fig:tsvmodel}
\end{figure}

For this model, there exist some methods and algorithms that successfully decompose a traffic surveillance video into the background and foreground components such as the Gaussian Mixture Model and Robust Principal Component Analysis (see [X] for \DIFaddbegin \DIFadd{an extensive }\DIFaddend review on this decomposition). In this work, we will use a modified version of the Tensor Robust Principal Component Analysis or \DIFdelbegin \DIFdel{TRPCA }\DIFdelend \DIFaddbegin \DIFadd{t-RPCA }\DIFaddend in short, originally proposed by Lu, C., et. al., [X] to achieve such decomposition.

\subsection{Moving Vehicle Traffic Tensor Modeling}

From the foreground tensor $\mathten{F}$, information about moving vehicles can be extracted such as their trajectory, geometry, kinematic \DIFdelbegin \DIFdel{and color informationby analyzing e.g., the connected components or the historical motion data in $\mathten{F}_m$}\DIFdelend \DIFaddbegin \DIFadd{or color information}\DIFaddend , which can be used later at a particular stage \DIFdelbegin \DIFdel{on a traffic surveillance }\DIFdelend \DIFaddbegin \DIFadd{of a VTS }\DIFaddend system. However, due to the \DIFdelbegin \DIFdel{high volume and the multi-mode nature of the data }\DIFdelend \DIFaddbegin \DIFadd{high-volume of data and multimodality induced by multi-stage VTS systems}\DIFaddend , a one-mode representation results to be not enough to exploit \DIFdelbegin \DIFdel{relations among all modes}\DIFdelend \DIFaddbegin \DIFadd{interactions among stages}\DIFaddend .

To tackle the shortcomings of one-mode models, we proposed to arrange and group \DIFdelbegin \DIFdel{the moving vehicle data into }\DIFdelend \DIFaddbegin \DIFadd{vehicle information as }\DIFaddend a high-order \DIFdelbegin \DIFdel{tensor $\mathten{T} \in \mathbb{R}^{I_1 \times \cdots \times I_N}$, which will be called here }\DIFdelend \DIFaddbegin \DIFadd{structure $\mathten{T}^{(N)} \in \mathbb{R}^{I_1 \times \cdots \times I_N}$ called }\DIFaddend Vehicle Traffic Feature \DIFdelbegin \DIFdel{tensor, where its order $ord(\mathten{T}) = N$ will be equal to the number of data models to be used. Therefore, whenever we want to include a new data model, the order of the VTF tensor will increase by one.
This makes it possible to have a flexible model in the face of new data models. 
}\DIFdelend \DIFaddbegin \DIFadd{(VTF) tensor to model the vehicle behavior of a feature model over multiple stages. Even though there is a vast set of features which can be extracted from $\mathten{F}$, here we will focus on the geometric feature model, for which we will assume that the behavior of any feature over time can be described by polynomial functions.
}\DIFaddend 


\DIFdelbegin \DIFdel{Unless otherwise stated, in the following sections we will refer to the VTF tensor as the five-order tensor with the following dimensions: $Vehicles \times Geometric\,Features \times Time \times Classification \times Occlusion$.
QUIZA ESTO MEJOR EN LOS EXPERIMENTOS.
}\DIFdelend %DIF > , where the superscript $(N)$ denotes the number of data models embedded on it, in other words its order $N=ord(\mathten{T}^{(N)})$. Therefore, whenever we want to include a new data model, the order of the VTF tensor will increase by one. This will enable us to have a flexible model in the face of new data models.

\DIFdelbegin \subsection{\DIFdel{Factorization of the Vehicle Traffic Feature Tensor}}
%DIFAUXCMD
\addtocounter{subsection}{-1}%DIFAUXCMD
\DIFdel{Although we can extract a bunch set of multidimensional information to our VFT tensor in different ways, we will focus our attention on two fundamental problems: the pattern recognition and the use of multilinear transformations to enforce low-rank assumptions on tensor models. We start by analyzing the pattern recognition followed by multilinear transformations.}\DIFdelend %DIF > In order to construct $\mathten{T}^{(N)}$, during a certain amount of time and for each detected vehicle on the road, we will record a set of geometric features modeled as vectors in $\mathbb{R}^n$, such as area, while assuming that within the observation time, $M$ vehicles will be detected and tracked. Based on these principles, we arrange the recorded data associated to the $i$th vehicle into a matrix $\mathmat{T}_i \in \mathbb{R}^{Geometric\,Features \times Time}$, such that each $\mathmat{T}_i$ will be stacked to form a new tensor $\mathten{T}^{(3)} \in \mathbb{R}^{Vehicle \times Geometric\,Features \times Time}$ or the third-order VTF tensor which will model the behavior of the vehicle geometric features over time.

\DIFdelbegin \subsubsection{\DIFdel{Pattern Recognition}}
%DIFAUXCMD
\addtocounter{subsubsection}{-1}%DIFAUXCMD
\DIFdel{Through the VTF tensor we can exploit the multi-mode correlations, for example, classification-mode, occlusion-mode, and temporal-mode, by Tensor Decompositions (TD), which provide a powerful analytical tool for dealing with multidimensional statics. Common TD employed include the CP-decomposition, Tucker model, HoSVD, and an SVD-based on the t-product called t-SVD, where the choice of a particular decomposition must be application dependent.The CP model is generally used for latent factor extraction, while the Tucker model to uncover hidden pattern in data.On the other hand, the choice of the t-SVD is more suitable when dealing with oriented-tensors}\DIFdelend \DIFaddbegin \DIFadd{In order to construct $\mathten{T}^{(N)}$, for each detected vehicle on the road, we will record a set of geometric features modeled as vectors in $\mathbb{R}^n$ during a certain amount of time, while assuming that within the observation time, $M$ vehicles will be detected and tracked. Based on these principles, we arrange the historical data of the $i$th vehicle into a matrix $\mathmat{T}_i \in \mathbb{R}^{F \times t}$, where $F$ denotes the number of features, and $t$ the time. Then, each $\mathmat{T}_i$ will be stacked along the third-dimension, such that the VTF tensor $\mathten{T}^{(3)}$ of Equation \ref{eq:vtf3model} will be formed to model the temporal behavior of the vehicles geometric features.
%DIF > Timestamp
}

\begin{equation}
\DIFadd{\mathten{T}^{(3)} \in \mathbb{R}^{Vehicle \times Geometric\,Features \times Time}
\label{eq:vtf3model}
}\end{equation}

\DIFadd{Following the above ideas, additional modes can also be added for a more generalized modeling of the vehicle geometric features. Specifically, in addition to the three modes of vehicles, geometric features and time, we also include the classification and occlusion modes using the VTF tensor model $\mathten{T}^{(5)}$ as Equation \ref{eq:vtf5model} shows to extend our analysis to multiple stages. In this setting, the classification mode will categorize vehicles according to their sizes (e.g., small, midsize, and large), while the occlusion mode, the type of occlusion }[] \DIFadd{(e.g., non-occluded, lateral, and queue occlusions)}\DIFaddend .

\DIFaddbegin \begin{equation}
\DIFadd{\mathten{T}^{(5)} \in \mathbb{R}^{Vehicles \times Geometric\,Features \times Time \times Classification \times Occlusion}
\label{eq:vtf5model}
}\end{equation}

\DIFaddend \subsubsection{\DIFdelbegin \DIFdel{Low-rankness by }\DIFdelend Multilinear Transformations \DIFaddbegin \DIFadd{over the Vehicle Traffic Feature Tensor}\DIFaddend }
For \DIFdelbegin \DIFdel{pattern learning in data, tensor decompositions }\DIFdelend \DIFaddbegin \DIFadd{any problem which involves the use of tensor structures, TD }\DIFaddend allow us to  exploit the \DIFdelbegin \DIFdel{high-dimensional structure of the input space}\DIFdelend \DIFaddbegin \DIFadd{intrinsic high-order structure of data}\DIFaddend , therefore, choosing an appropriate representation of data is a key component to improve \DIFdelbegin \DIFdel{pattern recognition}\DIFdelend \DIFaddbegin \DIFadd{any decomposition model}\DIFaddend . Multilinear transformations\DIFaddbegin \DIFadd{, which }\DIFaddend aim to express a multidimensional \DIFaddbegin \DIFadd{vector }\DIFaddend space $V_1 \times \cdots \times V_n$ as their multilinear combination by applying some mapping function \DIFdelbegin \DIFdel{, i.e., }\DIFdelend \DIFaddbegin \DIFadd{of several variables }\DIFaddend $f : V_1 \times \cdots \times V_n \rightarrow W$ \DIFdelbegin \DIFdel{, where $V_i$ and $W$ are vector spaces. It allows to find several representations of data that will }\DIFdelend \DIFaddbegin \DIFadd{that is linear separately in each variable, allow to find new data representations that could }\DIFaddend be more suitable for a particular \DIFdelbegin \DIFdel{tensor decomposition model}\DIFdelend \DIFaddbegin \DIFadd{TD}\DIFaddend .


\DIFdelbegin \DIFdel{As for }\DIFdelend \DIFaddbegin \DIFadd{Similar to }\DIFaddend linear transformations, \DIFdelbegin \DIFdel{a multilinear transformation provides different properties than }\DIFdelend \DIFaddbegin \DIFadd{multilinear transformations also provide us different properties or structures }[] \DIFadd{that }\DIFaddend can be exploited according to the problem faced, hence the use of a \DIFdelbegin \DIFdel{certain transformation will be also }\DIFdelend \DIFaddbegin \DIFadd{particular transformation must be }\DIFaddend application dependent. Here, we will seek for those \DIFdelbegin \DIFdel{multilinear }\DIFdelend functions which provide a higher-order representation of data while \DIFdelbegin \DIFdel{preserving intrinsic low-rank structures. These properties }\DIFdelend \DIFaddbegin \DIFadd{inducing well-known intrinsic structures. The first desired property }\DIFaddend will be needed for both preserving linear mixtures of the \DIFdelbegin \DIFdel{input }\DIFdelend \DIFaddbegin \DIFadd{source }\DIFaddend space and avoiding \DIFaddbegin \DIFadd{to introduce }\DIFaddend non-separable terms \DIFdelbegin \DIFdel{to }\DIFdelend \DIFaddbegin []\DIFadd{, while the second property allows to enjoy useful properties to }\DIFaddend be exploited in \DIFdelbegin \DIFdel{tensors decomposition}\DIFdelend \DIFaddbegin \DIFadd{TD}\DIFaddend . For that purpose, we \DIFdelbegin \DIFdel{employ two }\DIFdelend \DIFaddbegin \DIFadd{employed two deterministic }\DIFaddend multilinear transformations called Hankelization and L{\"o}wnerization [], which map the \DIFdelbegin \DIFdel{input space to }\DIFdelend \DIFaddbegin \DIFadd{source space into a }\DIFaddend higher-order \DIFdelbegin \DIFdel{representations that approximately have }\DIFdelend \DIFaddbegin \DIFadd{structure that have approximately a intrinsic }\DIFaddend low multilinear-rank\DIFdelbegin \DIFdel{, where }\DIFdelend \DIFaddbegin \DIFadd{. On the other hand, these transformations enjoy some useful properties for data modeling, for example, }\DIFaddend Hankel structures are known \DIFdelbegin \DIFdel{to represent exponential polynomials }\DIFdelend \DIFaddbegin \DIFadd{for representing exponential polynomials }[]\DIFaddend , while L{\"o}wner structures show a very close relationship with rational functions \DIFaddbegin []\DIFaddend , so that they can be used to model and approximate a \DIFaddbegin \DIFadd{wide }\DIFaddend variety of functions\DIFdelbegin \DIFdel{such as sinusoidals}\DIFdelend .

The $K$th-order Hankelization is a transformation that maps a vector \DIFdelbegin \DIFdel{$\mathvec{x}\in\mathbb{K}^N$ }\DIFdelend \DIFaddbegin \DIFadd{$\mathvec{x}\in\mathbb{R}^N$ }\DIFaddend into a $K$-order tensor \DIFdelbegin \DIFdel{$\mathten{H}^{(K)} \in\mathbb{K}^{I_1 \times \cdots \times I_K}$ }\DIFdelend \DIFaddbegin \DIFadd{$\mathten{H}^{(K)} \in\mathbb{R}^{I_1 \times \cdots \times I_K}$ }\DIFaddend called Hankel tensor \DIFdelbegin \DIFdel{which contain }\DIFdelend \DIFaddbegin \DIFadd{with constant }\DIFaddend anti-diagonal \DIFdelbegin \DIFdel{hyperplanes with constant entries defined by Equation \ref{eq:hankelization} }\DIFdelend \DIFaddbegin \DIFadd{hyperplanes as Equation \ref{eq:hankelization} shows}\DIFaddend , where $\mathcal{H}$ represents the Hankelization transformation, and $N = I_1 + \cdots + I_K - K + 1$.  On the other hand, the $K$th-order L{\"o}wnerization is a transformation that maps a \DIFdelbegin \DIFdel{vector $\mathvec{x}\in\mathbb{K}^N$ }\DIFdelend \DIFaddbegin \DIFadd{vectorized function $\mathvec{f}\in\mathbb{R}^N$ evaluated at $N$ points $\boldsymbol{\phi}\in\mathbb{R}^{N}$ }\DIFaddend into a $K$-order tensor \DIFdelbegin \DIFdel{$\mathten{L}\in\mathbb{K}^{I_1 \times \cdots \times I_K}$ }\DIFdelend \DIFaddbegin \DIFadd{$\mathten{L}^{(K)} \in \mathbb{R}^{I_1 \times \cdots \times I_K}$ }\DIFaddend called L{\"o}wner tensor such that each entry is defined as Equation \ref{eq:loewnerization} shows, where \DIFdelbegin \DIFdel{$\phi_{i_k}^{(k)}$ represents ASASASAS, while $f_{i_p}^{(p)}$ BLABLABLA.
The above ideas can also be extended to higher-order tensors in a straightforward way. }\DIFdelend \DIFaddbegin \DIFadd{$\mathcal{L}$ represents the $K$th-order L}{\DIFadd{\"o}}\DIFadd{wnerization transformation, while $\mathvec{f}^{(p)}$ is the $p$th subset of $\boldsymbol{\phi}$, which holds that  $\mathvec{f}^{(p)} \bigcap \mathvec{f}^{(q)} = \boldsymbol{\emptyset}$ and $\boldsymbol{\phi}=\bigcup_{k=1}^{K} {\mathvec{f}^{(k)}}$.
}\DIFaddend 

\DIFdelbegin \begin{displaymath}
\DIFdel{\mathten{H}^{(K)} = \mathcal{H}(\mathvec{x}) : \mathten{H}^{(K)}_{:,:,i_3,\cdots,i_K} = \mathcal{H}(\mathten{H}^{(K-1)}_{:,i_3,\cdots,i_K}), \, h^{(K)}_{i_1,\cdots,i_K} = x_{i_1 + \cdots + i_K - K + 1}
%DIFDELCMD < \label{eq:hankelization}%%%
}\end{displaymath}%DIFAUXCMD
\DIFdelend \DIFaddbegin \begin{equation}
\DIFadd{\mathten{H}^{(K)} = \mathcal{H}(\mathvec{x}) :  h^{(K)}_{i_1,\cdots,i_K} = x_{i_1 + \cdots + i_K - K + 1} %DIF >  \mathten{H}^{(K)}_{:,:,i_3,\cdots,i_K} = \mathcal{H}(\mathten{H}^{(K-1)}_{:,i_3,\cdots,i_K}), \,
\label{eq:hankelization}
}\end{equation}\DIFaddend 

\DIFdelbegin \begin{displaymath}
\DIFdel{\mathten{L} = \mathcal{L}(\mathvec{x}) : \ell_{i_1,\cdots,i_K} = \sum_{k=1}^{K}{\frac{x_{\phi_{i_k}}^{(k)}}{\prod_{m=1,m\neq k}^{K}{(f_{i_k}^{(k)}-f_{i_m}^{(m)})}}}
%DIFDELCMD < \label{eq:loewnerization}%%%
}\end{displaymath}%DIFAUXCMD
\DIFdelend \DIFaddbegin \begin{equation}
\DIFadd{\mathten{L}^{(K)} = \mathcal{L}(\mathvec{x}) : \ell_{i_1,\cdots,i_K} = \sum_{k=1}^{K}{ \frac{x_{\phi_{k}^{(k)}}}{\prod_{m=1,m\neq k}^{K}{(f_{k}^{(k)} - f_m^{(m)})}}}
\label{eq:loewnerization}
}\end{equation}\DIFaddend 

\DIFaddbegin \DIFadd{An example of the second-order Hankelization and  L}{\DIFadd{\"o}}\DIFadd{wnerization transformations are shown in Equations \ref{eq:hankelsample} and \ref{eq:loewnersample} respectively. In Equation \ref{eq:loewnersample}, it is assumed that the set of evaluation points is $\mathvec{t}=\{1,\:\:2,\:\:3,\:\:4\}$ which is partitioned into the two disjoint subsets $\mathvec{f}_1=\{1,\:\:3\}$ and $\mathvec{f}_2=\{2,\:\:4\}$.
}

\begin{equation}
	\DIFadd{\mathten{H}^{(2)} = \mathcal{H}\left(
	\begin{bmatrix}
		7 & 6 & 15 & 12
	\end{bmatrix}
	\right) =
	\begin{bmatrix}
	7 & 6 & 15 \\
	6 & 15 & 12
	\end{bmatrix}
	\label{eq:hankelsample}
}\end{equation}

\begin{equation}
	\DIFadd{\mathten{L}^{(2)} = \mathcal{L}\left(
	\begin{bmatrix}
	7 & 6 & 15 & 12
	\end{bmatrix}
	\right) = 
	\begin{bmatrix}
	\frac{7-6}{1-2} &  \frac{7-12}{1-4} \\
	\\
	 \frac{15-6}{3-2} & \frac{15-12}{3-4}
	\end{bmatrix}
	=
	\begin{bmatrix}
	-1.0000 &  1.6667 \\
	9.0000 & -3.0000
	\end{bmatrix}	
	\label{eq:loewnersample}
}\end{equation}

\DIFadd{While the use of these transformations appear to be beneficial to exploit low-rank models in TD, an increase in the volume of the ambient space is inevitable due to the introduced redundancy. To alleviate the curse of dimensionality induced by these transformations, we must exploit the intrinsic structures of Hankel and L}{\DIFadd{\"o}}\DIFadd{wner. For instance, a tensor–vector multiplication involving a Hankel tensor $\mathten{H}^{K} \in \mathbb{R}^{I_1 \times \cdots \times I_K}$ can be performed in $\mathcal{O}(N \log(N))$ flops using the FFT }[] \DIFadd{instead of the original $\mathcal{O}(\prod_{k=1}^{K} I_k)$ flops required with the naive operation, where $N=\sum_{k=1}^{K} I_k$. Similar to the Hankel case, L}{\DIFadd{\"o}}\DIFadd{wner structures can avoid the curse of dimensionality in the case of equidistant points }[]\DIFadd{.
}

%DIF > While applying these transformations provide us low-rank intrinsic structures on data, it is inevitable to increase the dimensionality of the ambient space of the source space. To alleviate the curse of dimensionality induced by these transformations, we must exploit the intrinsic structures of Hankel and L{\"o}wner. For instance, a tensor–vector multiplication involving a Hankel tensor $\mathten{H}^{K} \in \mathbb{R}^{I_1 \times \cdots \times I_K}$ can be performed in $\mathcal{O}(N \log(N))$ flops with $N=\sum_{k=1}^{K} I_k$ using the Fast Fourier Transform instead of the original flops $\mathcal{O}(\prod_{k=1}^{K}) I_k$ required with the naive operation []. Similar to Hankel, L{\"o}wner structures can avoid the curse of dimensionality in the case of equidistant points [].

\subsection{\DIFadd{Factorization of the Vehicle Traffic Feature Tensor}}
\DIFadd{Although we can extract a bunch set of multidimensional information to our VFT tensor in different ways, we will focus our attention on two fundamental problems: the pattern recognition and the use of multilinear transformations to enforce low-rank assumptions on tensor models. We start by analyzing the pattern recognition followed by low-rank models under multilinear transformations.
}

\subsubsection{\DIFadd{Pattern Recognition}}
\DIFadd{Through the VTF model we can exploit multi-mode correlations by Tensor Decompositions (TD), which provide a powerful analytical tool for dealing with multidimensional statics. Common TD employed include the CP-decomposition, Tucker model, HoSVD, and an SVD-based on the t-product called t-SVD, where the choice of a particular decomposition must be application dependent. The CP model is generally used for latent factor extraction, while the Tucker model to uncover hidden pattern in data. On the other hand, the choice of the t-SVD is more suitable when dealing with oriented-tensors.
}

\subsubsection{\DIFadd{Low-rank by Multilinear Transformations}}
%DIF > A classical model employed in many real-world applications is the (multidimensional) low-rank signal model [], which states that any measurement tensor $\mathten{X}\in\mathbb{R}^{I_1\times \cdots I_N}$ can be approximately decomposed as the sum of two components, a low-rank tensor $\mathten{L}\in\mathbb{R}^{I_1\times \cdots I_N}$, and a small Independent and Identically Distributed (IID) dense noise tensor $\mathten{N}\in\mathbb{R}^{I_1\times \cdots I_N}$, i.e., $\mathten{X} = \mathten{L} + \mathten{N}$.

\DIFaddend A \DIFdelbegin \DIFdel{common model used in many problems }\DIFdelend \DIFaddbegin \DIFadd{classical model employed in many real-world applications }\DIFaddend is the (multidimensional) low-rank \DIFdelbegin \DIFdel{signal model (see Equation \ref{eq:lowrankmodel}) }\DIFdelend \DIFaddbegin \DIFadd{model (LRM) }[]\DIFaddend , which states that any \DIFdelbegin \DIFdel{observable tensor $\mathten{X}\in\mathbb{K}^{I_1\times \cdots I_N}$ can be (approximately) decomposed }\DIFdelend \DIFaddbegin \DIFadd{measurement tensor $\mathten{X}\in\mathbb{R}^{I_1\times \cdots I_N}$ can be approximated }\DIFaddend as the sum of two components, a low-rank tensor \DIFdelbegin \DIFdel{$\mathten{L}\in\mathbb{K}^{I_1\times \cdots I_N}$}\DIFdelend \DIFaddbegin \DIFadd{$\mathten{L}\in\mathbb{R}^{I_1\times \cdots I_N}$}\DIFaddend , and a small dense noise \DIFdelbegin \DIFdel{tensor $\mathten{N}\in\mathbb{K}^{I_1\times \cdots I_N}$.Although this decomposition can be solved by several tensor models, such as Tucker, CP, t-SVD or t-RPCA decompositions (see Section \ref{sec:tensoralg}), we only analyze  the t-SVD and t-RPCA. }\DIFdelend \DIFaddbegin \DIFadd{or approximation error tensor $\mathten{N}\in\mathbb{R}^{I_1\times \cdots I_N}$, i.e., $\mathten{X} = \mathten{L} \simeq \mathten{N}$. This model is posed as an optimization problem, where in its simplest form, it can be formulated by minimizing the Frobenius norm  as Equation \ref{eq:lowrankmodel} shows.
}\DIFaddend 

\DIFaddbegin \begin{equation}
\DIFadd{\min_{\mathten{L}} }{\DIFadd{\left\lVert \mathten{X}-\mathten{L} \right\rVert}}\DIFadd{_{F}^2
\label{eq:lowrankmodel}
}\end{equation}



\DIFadd{However, the brittleness of LRM with respect to grossly corrupted observations, often causes non optimal solutions }[]\DIFadd{. For this reason, it is very common to replace \ref{eq:lowrankmodel} by its robust version $\mathten{X} \simeq \mathten{L} + \mathten{S} + \mathten{N}$ called Robust LRM (RLRM), which is commonly formulated as the minimization problem of Equation \ref{eq:lowrankmodel2}, where $\left\lVert \cdot \right\rVert_\star$ denotes the tensor nuclear norm, $\left\lVert \cdot \right\rVert_1$ the $L_1$-norm, and $\mathten{S}\in\mathbb{R}^{I_1\times \cdots I_N}$ a sparse component which models grossly corruptions. This decomposition model can be consider as a generalization of Equation \ref{eq:lowrankmodel}, since in the case of free-corruption, Equation \ref{eq:lowrankmodel2} is equivalent to \ref{eq:lowrankmodel}.
}

\DIFaddend \begin{equation}
\DIFdelbegin \DIFdel{\mathten{X}= }\DIFdelend \DIFaddbegin \DIFadd{\min_{\mathten{L,S}} }{\left\lVert\DIFaddend \mathten{L}\DIFaddbegin \right\rVert\DIFadd{_\star }\DIFaddend + \DIFdelbegin \DIFdel{\mathten{N}
}%DIFDELCMD < \label{eq:lowrankmodel}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \left\lVert\DIFadd{\mathten{S}}\right\rVert\DIFadd{_1}}
\label{eq:lowrankmodel2}
\DIFaddend \end{equation}

\DIFdelbegin \DIFdel{PREVIO A LA APLICACION DE LAS DESCOMPOSICIONES TENSORIALES, SE PRETENDE USAR LAS TRANSFORMACIONES DE HANKEL Y LOEWNER:
HANKEL PROVE ESTRUCTURAS DE BAJO RANGO EN EL CASO DE SIN-RUIDO, SIN EMBARGO EN GENERAL ESTO NO SE TIENE EN LA PRACTICA, POR LO TANTO PARA MODELAR LAS CARACTERISTICAS GEOMETRICAS Y CINEMATICASDE NUESTRO TENSOR. POR OTRO LADO EL MODELADO DE LAS CARACTERISTICAS COMO FUNCIONES RACIONALES.}\DIFdelend %DIF > From most of the TD such as the Tucker, CP and t-SVD decompositions, we can estimate $\mathten{L}$ and $\mathten{N}$, while from just a few decompositions, e.g., t-RPCA, to $\mathten{S}$. Although low-rank models are not limited to the use of specific decompositions, here we will only focus on the use of t-SVD and t-RPCA decompositions for solving Equations \ref{eq:lowrankmodel} and \ref{eq:lowrankmodel2} respectively. 

\DIFaddbegin \DIFadd{Although there exist many related works that successfully solve these models }[\DIFadd{15, 34}]\DIFadd{, the RLRM lacks optimality when the intrinsic structure of a tensor is of high-rank, a situation that often happen in practice, which leads to a global solution that is not exactly low-rank. However, recently Li, C., et. al, }[\DIFadd{x}]\DIFadd{, showed that a low-rank based matrix completion problem can obtain better performance by exploiting the low-rank structure resulted after transforming an observed matrix $\mathmat{X}\in\mathbb{R}^{m \times n}$ into a new representation $\mathmat{Y}\in\mathbb{R}^{m \times n}$ by applying a set of $K$ linear transformations $\{\mathcal{Q}_i(\cdot)\}_{i=1}^K$, ideas that established the foundations for a framework called Matrix Completion under Multiple linear Transformations (MCMT). MCMT is formulated as an optimization problem (see Equation \ref{eq:mcmtmodel}), where $\mathcal{P}_\Omega(\cdot)$ denotes a downsampling operation over the supporting set $\Omega$, and $\delta\in\mathbb{R}^+$ a small constant.
}

\begin{equation}
	\DIFadd{\begin{aligned}
		\min_{\mathmat{X}} \quad & {\sum_{i=1}^{K} \left\lVert \mathcal{Q}_i(\mathmat{X}) \right\rVert_*}\\
		\textrm{s.t.} \quad & \left\lVert \mathcal{P}_\Omega(\mathmat{X}) - \mathcal{P}_\Omega(\mathmat{Y}) \right\rVert_F < \delta
	\end{aligned}
\label{eq:mcmtmodel}
}\end{equation}

\DIFadd{Following the ideas behind MCMT on matrices, we propose the high-order RLRM under Multilinear Transformations (HoRLRM$^2$T) with applications to modeling and approximation of functions, where we exploit the additional multi-mode low-rank structures of the transformed tensors.
}\DIFaddend EMPLEAMOS LOS MODELOS SEGUIDOS DE UN TRUNCAMIENTO DE LA T-SVD, DESCARTANDO AQUELLOS VALORES SINGULARES MULTIDIMENSIONALES QUE NO APORTEN SUFICIENTE INFORMACION DE ACUERDO A SU DISTRIBUCION. ADICIONALMENTE EL USO DE T-RPCA PARA GENERAR MODELOS MAS ROBUSTOS FRENTE A CORRUPCION EN LOS DATOS.
\DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend PRESENTAR CONTRIBUCIONES EN EL MODELADO DE DATOS EN EL USO DE ESTAS DOS TRANSFORMACIONES, ASI COMO CARACTERISTICAS DE LOS TENSORES RESULTANTES COMO LO SON SUS RANGOS, TRABAJOS RELACIONADOS CON CP Y TUCKER.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments}

%This section may be divided by subheadings. It should provide a concise and precise description of the experimental results, their interpretation as well as the experimental conclusions that can be drawn.
%\begin{quote}
%This section may be divided by subheadings. It should provide a concise and precise description of the experimental results, their interpretation as well as the experimental conclusions that can be drawn.
%\end{quote}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Subsection}
%\unskip
%\subsubsection{Subsubsection}

%Bulleted lists look like this:
%\begin{itemize}[leftmargin=*,labelsep=5.8mm]
%\item	First bullet
%\item	Second bullet
%\item	Third bullet
%\end{itemize}

%Numbered lists can be added as follows:
%\begin{enumerate}[leftmargin=*,labelsep=4.9mm]
%\item	First item 
%\item	Second item
%\item	Third item
%\end{enumerate}

%The text continues here.

%\subsection{Figures, Tables and Schemes}
%
%All figures and tables should be cited in the main text as Figure 1, Table 1, etc.
%
%\begin{figure}[H]
%\centering
%\includegraphics[width=2 cm]{Definitions/logo-mdpi}
%\caption{This is a figure, Schemes follow the same formatting. If there are multiple panels, they should be listed as: (\textbf{a}) Description of what is contained in the first panel. (\textbf{b}) Description of what is contained in the second panel. Figures should be placed in the main text near to the first time they are cited. A caption on a single line should be centered.}
%\end{figure}   
% 
%Text
%
%Text
%
%\begin{table}[H]
%\caption{This is a table caption. Tables should be placed in the main text near to the first time they are cited.}
%\centering
%%% \tablesize{} %% You can specify the fontsize here, e.g., \tablesize{\footnotesize}. If commented out \small will be used.
%\begin{tabular}{ccc}
%\toprule
%\textbf{Title 1}	& \textbf{Title 2}	& \textbf{Title 3}\\
%\midrule
%entry 1		& data			& data\\
%entry 2		& data			& data\\
%\bottomrule
%\end{tabular}
%\end{table}

%Text
%
%Text

%\begin{listing}[H]
%\caption{Title of the listing}
%\rule{\textwidth}{1pt}
%\raggedright Text of the listing. In font size footnotesize, small, or normalsize. Preferred format: left aligned and single spaced. Preferred border format: top border line and bottom border line.
%\rule{\textwidth}{1pt}
%\end{listing}


%\subsection{Formatting of Mathematical Components}

%This is an example of an equation:
%
%\begin{equation}
%a + b = c
%\end{equation}
%% If the documentclass option "submit" is chosen, please insert a blank line before and after any math environment (equation and eqnarray environments). This ensures correct linenumbering. The blank line should be removed when the documentclass option is changed to "accept" because the text following an equation should not be a new paragraph. 

%Please punctuate equations as regular text. Theorem-type environments (including propositions, lemmas, corollaries etc.) can be formatted as follows:
%%% Example of a theorem:
%\begin{Theorem}
%Example text of a theorem.
%\end{Theorem}

%The text continues here. Proofs must be formatted as follows:
%
%%% Example of a proof:
%\begin{proof}[Proof of Theorem 1]
%Text of the proof. Note that the phrase `of Theorem 1' is optional if it is clear which theorem is being referred to.
%\end{proof}
%The text continues here.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}

Authors should discuss the results and how they can be interpreted in perspective of previous studies and of the working hypotheses. The findings and their implications should be discussed in the broadest context possible. Future research directions may also be highlighted.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Materials and Methods}
%
%Materials and Methods should be described with sufficient details to allow others to replicate and build on published results. Please note that publication of your manuscript implicates that you must make all materials, data, computer code, and protocols associated with the publication available to readers. Please disclose at the submission stage any restrictions on the availability of materials or information. New methods and protocols should be described in detail while well-established methods can be briefly described and appropriately cited.
%
%Research manuscripts reporting large datasets that are deposited in a publicly available database should specify where the data have been deposited and provide the relevant accession numbers. If the accession numbers have not yet been obtained at the time of submission, please state that they will be provided during review. They must be provided prior to publication.
%
%Interventionary studies involving animals or humans, and other studies require ethical approval must list the authority that provided approval and the corresponding ethical approval code. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}
CONCLUSIONES DEL LOW-RANK Y TRANSFORMACIONES, CUANDO CONOCEMOS LA FORMA ALGEBRAICA DE LAS CARACTERISTICAS SE EMPLEA HANKEL+T-SVD, DE OTRO MODO LOEWNER + T-RPCA, EL USO DE ESTOS MODELOS DE BAJO RANGO NOS AYUDAN A ELIMINAR DISTURBIOS EN LOS DATOS, CON LO CUAL SE PUEDE MEJORAR LOS MODELOS DE CLASIFICACION Y OCLUSION.
\DIFaddbegin \\
\\
\DIFadd{TRABAJO FUTURO: 1. USO DE TRANSFORMACIONES MULTI-LINEALES? ESTOCASTICAS, ASI  COMO NO LINEALES. 2. USO DE LAS DESCOMPOSICIONES TENSORIALES CON RESTRICCIONES ESTRUCTURADAS (HANKEL, LOEWNER, ETC), ASI COMO OTRAS RESTRICCIONES (NO NEGATIVIDAD).
}\DIFaddend 

\DIFdelbegin \DIFdel{This section is not mandatory, but can be added to the manuscript if the discussion is unusually long or complex. }\DIFdelend %DIF > This section is not mandatory, but can be added to the manuscript if the discussion is unusually long or complex.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Patents}
%This section is not mandatory, but may be added if there are patents resulting from the work reported in this manuscript.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{6pt} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
%\supplementary{The following are available online at \linksupplementary{s1}, Figure S1: title, Table S1: title, Video S1: title.}

% Only for the journal Methods and Protocols:
% If you wish to submit a video article, please do so with any other supplementary material.
% \supplementary{The following are available at \linksupplementary{s1}, Figure S1: title, Table S1: title, Video S1: title. A supporting video article is available at doi: link.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\authorcontributions{For research articles with several authors, a short paragraph specifying their individual contributions must be provided. The following statements should be used ``conceptualization, X.X. and Y.Y.; methodology, X.X.; software, X.X.; validation, X.X., Y.Y. and Z.Z.; formal analysis, X.X.; investigation, X.X.; resources, X.X.; data curation, X.X.; writing--original draft preparation, X.X.; writing--review and editing, X.X.; visualization, X.X.; supervision, X.X.; project administration, X.X.; funding acquisition, Y.Y.'', please turn to the  \href{http://img.mdpi.org/data/contributor-role-instruction.pdf}{CRediT taxonomy} for the term explanation. Authorship must be limited to those who have contributed substantially to the work reported.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\funding{Please add: ``This research received no external funding'' or ``This research was funded by NAME OF FUNDER grant number XXX.'' and  and ``The APC was funded by XXX''. Check carefully that the details given are accurate and use the standard spelling of funding agency names at \url{https://search.crossref.org/funding}, any errors may affect your future funding.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\acknowledgments{In this section you can acknowledge any support given which is not covered by the author contribution or funding sections. This may include administrative and technical support, or donations in kind (e.g., materials used for experiments).}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\conflictsofinterest{Declare conflicts of interest or state ``The authors declare no conflict of interest.'' Authors must identify and declare any personal circumstances or interest that may be perceived as inappropriately influencing the representation or interpretation of reported research results. Any role of the funders in the design of the study; in the collection, analyses or interpretation of data; in the writing of the manuscript, or in the decision to publish the results must be declared in this section. If there is no role, please state ``The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript, or in the decision to publish the results''.} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
\abbreviations{The following abbreviations are used in this manuscript:\\

\noindent 
\begin{tabular}{@{}ll}
MDPI & Multidisciplinary Digital Publishing Institute\\
DOAJ & Directory of open access journals\\
TLA & Three letter acronym\\
LD & linear dichroism
\end{tabular}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
%\appendixtitles{no} %Leave argument "no" if all appendix headings stay EMPTY (then no dot is printed after "Appendix A"). If the appendix sections contain a heading then change the argument to "yes".
%\appendix
%\section{}
%\unskip
%\subsection{}
%The appendix is an optional section that can contain details and data supplemental to the main text. For example, explanations of experimental details that would disrupt the flow of the main text, but nonetheless remain crucial to understanding and reproducing the research shown; figures of replicates for experiments of which representative data is shown in the main text can be added here if brief, or as Supplementary data. Mathematical proofs of results not central to the paper can be added as an appendix.
%
%\section{}
%All appendix sections must be cited in the main text. In the appendixes, Figures, Tables, etc. should be labeled starting with `A', e.g., Figure A1, Figure A2, etc. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\reftitle{References}

% Please provide either the correct journal abbreviation (e.g. according to the “List of Title Word Abbreviations” http://www.issn.org/services/online-services/access-to-the-ltwa/) or the full name of the journal.
% Citations and References in Supplementary files are permitted provided that they also appear in the reference list here. 

%=====================================
% References, variant A: external bibliography
%=====================================
%\externalbibliography{yes}
%\bibliography{your_external_BibTeX_file}

%=====================================
% References, variant B: internal bibliography
%=====================================
\begin{thebibliography}{999}
% Reference 1
\bibitem[Author1(year)]{ref-journal}
Author1, T. The title of the cited article. {\em Journal Abbreviation} {\bf 2008}, {\em 10}, 142--149.
% Reference 2
\bibitem[Author2(year)]{ref-book}
Author2, L. The title of the cited contribution. In {\em The Book Title}; Editor1, F., Editor2, A., Eds.; Publishing House: City, Country, 2007; pp. 32--58.
\end{thebibliography}

% The following MDPI journals use author-date citation: Arts, Econometrics, Economies, Genealogy, Humanities, IJFS, JRFM, Laws, Religions, Risks, Social Sciences. For those journals, please follow the formatting guidelines on http://www.mdpi.com/authors/references
% To cite two works by the same author: \citeauthor{ref-journal-1a} (\citeyear{ref-journal-1a}, \citeyear{ref-journal-1b}). This produces: Whittaker (1967, 1975)
% To cite two works by the same author with specific pages: \citeauthor{ref-journal-3a} (\citeyear{ref-journal-3a}, p. 328; \citeyear{ref-journal-3b}, p.475). This produces: Wong (1999, p. 328; 2000, p. 475)


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
\sampleavailability{Samples of the compounds ...... are available from the authors.}

%% for journal Sci
%\reviewreports{\\
%Reviewer 1 comments and authors’ response\\
%Reviewer 2 comments and authors’ response\\
%Reviewer 3 comments and authors’ response
%}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}

